{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kya/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn import datasets, metrics, cross_validation\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=2017, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 400)\n",
    "\n",
    "    def train(self, xtra, ytra, xte, yte):\n",
    "        dtrain = xgb.DMatrix(xtra, label=ytra)\n",
    "        dvalid = xgb.DMatrix(xte, label=yte)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds,\n",
    "            watchlist, early_stopping_rounds=10)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "    \n",
    "class LgbWrapper(object):\n",
    "    def __init__(self, seed=2017, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 400)\n",
    "\n",
    "    def train(self, xtra, ytra, xte, yte):\n",
    "        ytra = ytra.ravel()\n",
    "        yte = yte.ravel()\n",
    "        dtrain = lgb.Dataset(xtra, label=ytra)\n",
    "        self.gbdt = lgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(x)\n",
    "\n",
    "class CtbWrapper(object):\n",
    "    def __init__(self, seed=2017, params=None):\n",
    "        self.seed = seed\n",
    "        self.nrounds = 300\n",
    "\n",
    "    def train(self, xtra, ytra, xte, yte):\n",
    "        self.gbdt = ctb.CatBoostRegressor(depth=10,\n",
    "            iterations=self.nrounds, random_seed=self.seed,\n",
    "            use_best_model=True, loss_function='RMSE',\n",
    "            thread_count=8, eval_metric='RMSE')\n",
    "\n",
    "        xtra = pd.DataFrame(xtra)\n",
    "        ytra = pd.DataFrame(ytra)\n",
    "        xte = pd.DataFrame(xte)\n",
    "        yte = pd.DataFrame(yte)\n",
    "\n",
    "        self.gbdt.fit(X=xtra, y=ytra, eval_set=(xte, yte),\n",
    "                      use_best_model=True)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(x)\n",
    "\n",
    "class lrWrapper(object):\n",
    "    def __init__(self, seed=2017, params=None):\n",
    "        self.seed = seed\n",
    "\n",
    "    def train(self, xtra, ytra, xte, yte):\n",
    "        self.clf = LogisticRegression()\n",
    "        xtra = pd.DataFrame(xtra)\n",
    "        ytra = pd.DataFrame(ytra)\n",
    "        self.clf.fit(X=xtra, y=ytra)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, ntrain, ntest, kf, train, labels, test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((5, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = train[train_index]\n",
    "        y_tr = labels[train_index]\n",
    "        x_te = train[test_index]\n",
    "        y_te = labels[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr, x_te, y_te)\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(train, labels, test):\n",
    "\n",
    "    ntrain = train.shape[0]\n",
    "    ntest = test.shape[0]\n",
    "\n",
    "    kf = KFold(ntrain, n_folds=5,\n",
    "               shuffle=True, random_state=2017)\n",
    "\n",
    "    lgb_params = {}\n",
    "    lgb_params['boosting_type'] = 'gbdt'\n",
    "    lgb_params['objective'] = 'regression'\n",
    "    lgb_params['metric'] = 'auc'\n",
    "    lgb_params['num_leaves'] = 96\n",
    "    lgb_params['max_depth'] = 7\n",
    "    lgb_params['feature_fraction'] = 0.9\n",
    "    lgb_params['bagging_fraction'] = 0.95\n",
    "    lgb_params['bagging_freq'] = 5\n",
    "    lgb_params['learning_rate'] = 0.1\n",
    "\n",
    "\n",
    "    xgb_params = {}\n",
    "    xgb_params['booster'] = 'gbtree'\n",
    "    xgb_params['silent'] = 1\n",
    "    xgb_params['colsample_bytree'] = 0.15\n",
    "    xgb_params['eta'] = 0.09\n",
    "    xgb_params['eval_metric'] = 'auc'\n",
    "    xgb_params['gamma'] = 0.7\n",
    "    xgb_params['max_depth'] = 12\n",
    "    xgb_params['min_child_weight'] = 5.0\n",
    "    xgb_params['n_estimators'] = 720\n",
    "    xgb_params['objective'] = 'binary:logistic'\n",
    "    xgb_params['subsample'] = 0.9\n",
    "    \n",
    "    \n",
    "    cg = CtbWrapper()\n",
    "    xg = XgbWrapper(seed=2017, params=xgb_params)\n",
    "    lg = LgbWrapper(seed=2017, params=lgb_params)\n",
    "    lr = lrWrapper()\n",
    "\n",
    "    lg_oof_train, lg_oof_test = get_oof(lg, ntrain, ntest, kf, train, labels, test)\n",
    "    xg_oof_train, xg_oof_test = get_oof(xg, ntrain, ntest, kf, train, labels, test)\n",
    "    cg_oof_train, cg_oof_test = get_oof(cg, ntrain, ntest, kf, train, labels, test)\n",
    "    lr_oof_train, lr_oof_test = get_oof(lr, ntrain, ntest, kf, train, labels, test)\n",
    "\n",
    "    x_train = np.concatenate((lr_oof_train, cg_oof_train, xg_oof_train, lg_oof_train), axis=1)\n",
    "    x_test = np.concatenate((lr_oof_test, cg_oof_test, xg_oof_test, lg_oof_test), axis=1)\n",
    "\n",
    "    np.save(arr=x_train, file='x_concat_train.npy')\n",
    "    np.save(arr=x_test, file='x_concat_test.npy')\n",
    "    np.save(arr=labels, file='y_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    train = np.load('x_concat_train.npy')\n",
    "    labels = np.load('y_labels.npy')\n",
    "    test = np.load('x_concat_test.npy')\n",
    "\n",
    "    dtrain = xgb.DMatrix(train, label=labels)\n",
    "    dtest = xgb.DMatrix(test)\n",
    "\n",
    "    xgb_params = {}\n",
    "    xgb_params[\"objective\"] = \"binary:logistic\"\n",
    "    xgb_params[\"eta\"] = 0.1\n",
    "    xgb_params[\"subsample\"] = 0.9\n",
    "    xgb_params[\"silent\"] = 1\n",
    "    xgb_params[\"max_depth\"] = 6\n",
    "    xgb_params['eval_metric'] = 'auc'\n",
    "    xgb_params['min_child_weight'] = 10\n",
    "    xgb_params['seed'] = 2017\n",
    "\n",
    "    res = xgb.cv(xgb_params, dtrain, num_boost_round=500, nfold=5, seed=2017, stratified=False,\n",
    "                 early_stopping_rounds=25, verbose_eval=10, show_stdv=True)\n",
    "\n",
    "    best_nrounds = res.shape[0] - 1\n",
    "    cv_mean = res.iloc[-1, 0]\n",
    "    cv_std = res.iloc[-1, 1]\n",
    "\n",
    "    print('')\n",
    "    print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
    "    bst = xgb.train(xgb_params, dtrain, best_nrounds)\n",
    "\n",
    "    return bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_data = pd.read_csv(\"train_fe_finish.txt\", index_col=0)\n",
    "    test_data = pd.read_csv(\"test_fe_finish.txt\", index_col=0)\n",
    "\n",
    "    dfx_train, dflabels = train_data.drop(['rating'], axis=1), train_data['rating']\n",
    "\n",
    "    x_train = np.array(dfx_train)\n",
    "    x_test = np.array(test_data)\n",
    "    labels = np.array(dflabels)\n",
    "\n",
    "    model_1(x_train, labels, x_test)\n",
    "    preds = model_2()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.773953\teval-auc:0.681023\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.823458\teval-auc:0.746869\n",
      "[2]\ttrain-auc:0.836904\teval-auc:0.770937\n",
      "[3]\ttrain-auc:0.836931\teval-auc:0.772371\n",
      "[4]\ttrain-auc:0.839805\teval-auc:0.77748\n",
      "[5]\ttrain-auc:0.842228\teval-auc:0.782408\n",
      "[6]\ttrain-auc:0.844687\teval-auc:0.786435\n",
      "[7]\ttrain-auc:0.859585\teval-auc:0.790421\n",
      "[8]\ttrain-auc:0.866368\teval-auc:0.790291\n",
      "[9]\ttrain-auc:0.865201\teval-auc:0.792469\n",
      "[10]\ttrain-auc:0.864752\teval-auc:0.79298\n",
      "[11]\ttrain-auc:0.872151\teval-auc:0.793583\n",
      "[12]\ttrain-auc:0.870927\teval-auc:0.795379\n",
      "[13]\ttrain-auc:0.868912\teval-auc:0.796225\n",
      "[14]\ttrain-auc:0.876362\teval-auc:0.798741\n",
      "[15]\ttrain-auc:0.881358\teval-auc:0.798086\n",
      "[16]\ttrain-auc:0.880248\teval-auc:0.79892\n",
      "[17]\ttrain-auc:0.883859\teval-auc:0.798202\n",
      "[18]\ttrain-auc:0.882974\teval-auc:0.799433\n",
      "[19]\ttrain-auc:0.887497\teval-auc:0.799061\n",
      "[20]\ttrain-auc:0.887022\teval-auc:0.80033\n",
      "[21]\ttrain-auc:0.889859\teval-auc:0.80008\n",
      "[22]\ttrain-auc:0.889584\teval-auc:0.801841\n",
      "[23]\ttrain-auc:0.889263\teval-auc:0.803224\n",
      "[24]\ttrain-auc:0.889166\teval-auc:0.804409\n",
      "[25]\ttrain-auc:0.892742\teval-auc:0.805253\n",
      "[26]\ttrain-auc:0.896681\teval-auc:0.806434\n",
      "[27]\ttrain-auc:0.896536\teval-auc:0.806929\n",
      "[28]\ttrain-auc:0.899957\teval-auc:0.806329\n",
      "[29]\ttrain-auc:0.902815\teval-auc:0.807585\n",
      "[30]\ttrain-auc:0.902968\teval-auc:0.808366\n",
      "[31]\ttrain-auc:0.90637\teval-auc:0.808218\n",
      "[32]\ttrain-auc:0.90634\teval-auc:0.808922\n",
      "[33]\ttrain-auc:0.909032\teval-auc:0.809673\n",
      "[34]\ttrain-auc:0.913007\teval-auc:0.810982\n",
      "[35]\ttrain-auc:0.91285\teval-auc:0.811598\n",
      "[36]\ttrain-auc:0.915526\teval-auc:0.811495\n",
      "[37]\ttrain-auc:0.918593\teval-auc:0.811812\n",
      "[38]\ttrain-auc:0.921327\teval-auc:0.811824\n",
      "[39]\ttrain-auc:0.922855\teval-auc:0.811911\n",
      "[40]\ttrain-auc:0.92287\teval-auc:0.812655\n",
      "[41]\ttrain-auc:0.925434\teval-auc:0.81284\n",
      "[42]\ttrain-auc:0.925203\teval-auc:0.812639\n",
      "[43]\ttrain-auc:0.927243\teval-auc:0.811998\n",
      "[44]\ttrain-auc:0.927179\teval-auc:0.812313\n",
      "[45]\ttrain-auc:0.928361\teval-auc:0.812013\n",
      "[46]\ttrain-auc:0.92797\teval-auc:0.812174\n",
      "[47]\ttrain-auc:0.929936\teval-auc:0.811943\n",
      "[48]\ttrain-auc:0.931571\teval-auc:0.811547\n",
      "[49]\ttrain-auc:0.931659\teval-auc:0.811769\n",
      "[50]\ttrain-auc:0.932676\teval-auc:0.812229\n",
      "[51]\ttrain-auc:0.932704\teval-auc:0.812836\n",
      "Stopping. Best iteration:\n",
      "[41]\ttrain-auc:0.925434\teval-auc:0.81284\n",
      "\n",
      "[0]\ttrain-auc:0.783023\teval-auc:0.723511\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.826824\teval-auc:0.773926\n",
      "[2]\ttrain-auc:0.833136\teval-auc:0.783318\n",
      "[3]\ttrain-auc:0.83577\teval-auc:0.787153\n",
      "[4]\ttrain-auc:0.839119\teval-auc:0.7908\n",
      "[5]\ttrain-auc:0.842621\teval-auc:0.790498\n",
      "[6]\ttrain-auc:0.844319\teval-auc:0.790273\n",
      "[7]\ttrain-auc:0.857718\teval-auc:0.793167\n",
      "[8]\ttrain-auc:0.863392\teval-auc:0.792988\n",
      "[9]\ttrain-auc:0.863795\teval-auc:0.79383\n",
      "[10]\ttrain-auc:0.863216\teval-auc:0.793534\n",
      "[11]\ttrain-auc:0.87155\teval-auc:0.792854\n",
      "[12]\ttrain-auc:0.871\teval-auc:0.792392\n",
      "[13]\ttrain-auc:0.870297\teval-auc:0.792441\n",
      "[14]\ttrain-auc:0.877397\teval-auc:0.795339\n",
      "[15]\ttrain-auc:0.881812\teval-auc:0.795894\n",
      "[16]\ttrain-auc:0.881439\teval-auc:0.796841\n",
      "[17]\ttrain-auc:0.885324\teval-auc:0.797305\n",
      "[18]\ttrain-auc:0.885128\teval-auc:0.797449\n",
      "[19]\ttrain-auc:0.889379\teval-auc:0.797784\n",
      "[20]\ttrain-auc:0.888945\teval-auc:0.798556\n",
      "[21]\ttrain-auc:0.892223\teval-auc:0.799457\n",
      "[22]\ttrain-auc:0.891662\teval-auc:0.799542\n",
      "[23]\ttrain-auc:0.891534\teval-auc:0.799634\n",
      "[24]\ttrain-auc:0.891385\teval-auc:0.799731\n",
      "[25]\ttrain-auc:0.894872\teval-auc:0.800924\n",
      "[26]\ttrain-auc:0.898906\teval-auc:0.802431\n",
      "[27]\ttrain-auc:0.898736\teval-auc:0.803154\n",
      "[28]\ttrain-auc:0.901335\teval-auc:0.804555\n",
      "[29]\ttrain-auc:0.904948\teval-auc:0.805983\n",
      "[30]\ttrain-auc:0.904811\teval-auc:0.805665\n",
      "[31]\ttrain-auc:0.907514\teval-auc:0.806\n",
      "[32]\ttrain-auc:0.907134\teval-auc:0.806354\n",
      "[33]\ttrain-auc:0.910045\teval-auc:0.806773\n",
      "[34]\ttrain-auc:0.913865\teval-auc:0.808015\n",
      "[35]\ttrain-auc:0.913825\teval-auc:0.808037\n",
      "[36]\ttrain-auc:0.915614\teval-auc:0.808829\n",
      "[37]\ttrain-auc:0.919076\teval-auc:0.810117\n",
      "[38]\ttrain-auc:0.921754\teval-auc:0.811034\n",
      "[39]\ttrain-auc:0.92291\teval-auc:0.809902\n",
      "[40]\ttrain-auc:0.922596\teval-auc:0.810087\n",
      "[41]\ttrain-auc:0.925397\teval-auc:0.810716\n",
      "[42]\ttrain-auc:0.925138\teval-auc:0.810673\n",
      "[43]\ttrain-auc:0.927401\teval-auc:0.811338\n",
      "[44]\ttrain-auc:0.927083\teval-auc:0.811414\n",
      "[45]\ttrain-auc:0.928729\teval-auc:0.81135\n",
      "[46]\ttrain-auc:0.928827\teval-auc:0.81137\n",
      "[47]\ttrain-auc:0.930537\teval-auc:0.811728\n",
      "[48]\ttrain-auc:0.932078\teval-auc:0.81193\n",
      "[49]\ttrain-auc:0.931894\teval-auc:0.811993\n",
      "[50]\ttrain-auc:0.932838\teval-auc:0.810853\n",
      "[51]\ttrain-auc:0.932687\teval-auc:0.810958\n",
      "[52]\ttrain-auc:0.932579\teval-auc:0.81135\n",
      "[53]\ttrain-auc:0.932477\teval-auc:0.811378\n",
      "[54]\ttrain-auc:0.93228\teval-auc:0.811369\n",
      "[55]\ttrain-auc:0.932182\teval-auc:0.811288\n",
      "[56]\ttrain-auc:0.933257\teval-auc:0.811048\n",
      "[57]\ttrain-auc:0.934542\teval-auc:0.811509\n",
      "[58]\ttrain-auc:0.935722\teval-auc:0.811963\n",
      "[59]\ttrain-auc:0.936716\teval-auc:0.812214\n",
      "[60]\ttrain-auc:0.938678\teval-auc:0.812429\n",
      "[61]\ttrain-auc:0.941011\teval-auc:0.81256\n",
      "[62]\ttrain-auc:0.941926\teval-auc:0.81302\n",
      "[63]\ttrain-auc:0.942716\teval-auc:0.813476\n",
      "[64]\ttrain-auc:0.94278\teval-auc:0.813638\n",
      "[65]\ttrain-auc:0.942635\teval-auc:0.813405\n",
      "[66]\ttrain-auc:0.944459\teval-auc:0.813288\n",
      "[67]\ttrain-auc:0.945291\teval-auc:0.813139\n",
      "[68]\ttrain-auc:0.945283\teval-auc:0.813037\n",
      "[69]\ttrain-auc:0.94597\teval-auc:0.813182\n",
      "[70]\ttrain-auc:0.94655\teval-auc:0.81263\n",
      "[71]\ttrain-auc:0.946424\teval-auc:0.812662\n",
      "[72]\ttrain-auc:0.946426\teval-auc:0.813026\n",
      "[73]\ttrain-auc:0.946356\teval-auc:0.813069\n",
      "[74]\ttrain-auc:0.946277\teval-auc:0.812908\n",
      "Stopping. Best iteration:\n",
      "[64]\ttrain-auc:0.94278\teval-auc:0.813638\n",
      "\n",
      "[0]\ttrain-auc:0.738457\teval-auc:0.659343\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.822255\teval-auc:0.750734\n",
      "[2]\ttrain-auc:0.832015\teval-auc:0.765543\n",
      "[3]\ttrain-auc:0.834659\teval-auc:0.771297\n",
      "[4]\ttrain-auc:0.839239\teval-auc:0.776821\n",
      "[5]\ttrain-auc:0.841519\teval-auc:0.777365\n",
      "[6]\ttrain-auc:0.843305\teval-auc:0.782485\n",
      "[7]\ttrain-auc:0.853138\teval-auc:0.787066\n",
      "[8]\ttrain-auc:0.853815\teval-auc:0.788604\n",
      "[9]\ttrain-auc:0.853933\teval-auc:0.790086\n",
      "[10]\ttrain-auc:0.864472\teval-auc:0.79524\n",
      "[11]\ttrain-auc:0.864168\teval-auc:0.794485\n",
      "[12]\ttrain-auc:0.869241\teval-auc:0.796257\n",
      "[13]\ttrain-auc:0.868693\teval-auc:0.795596\n",
      "[14]\ttrain-auc:0.876367\teval-auc:0.801533\n",
      "[15]\ttrain-auc:0.875732\teval-auc:0.80189\n",
      "[16]\ttrain-auc:0.875699\teval-auc:0.802692\n",
      "[17]\ttrain-auc:0.874983\teval-auc:0.803242\n",
      "[18]\ttrain-auc:0.875035\teval-auc:0.804948\n",
      "[19]\ttrain-auc:0.88034\teval-auc:0.806623\n",
      "[20]\ttrain-auc:0.884114\teval-auc:0.807136\n",
      "[21]\ttrain-auc:0.887392\teval-auc:0.807673\n",
      "[22]\ttrain-auc:0.887093\teval-auc:0.808084\n",
      "[23]\ttrain-auc:0.890965\teval-auc:0.810314\n",
      "[24]\ttrain-auc:0.895068\teval-auc:0.811943\n",
      "[25]\ttrain-auc:0.894611\teval-auc:0.812183\n",
      "[26]\ttrain-auc:0.897872\teval-auc:0.814242\n",
      "[27]\ttrain-auc:0.897495\teval-auc:0.815024\n",
      "[28]\ttrain-auc:0.90213\teval-auc:0.81512\n",
      "[29]\ttrain-auc:0.901745\teval-auc:0.81516\n",
      "[30]\ttrain-auc:0.901281\teval-auc:0.814805\n",
      "[31]\ttrain-auc:0.905522\teval-auc:0.816967\n",
      "[32]\ttrain-auc:0.905418\teval-auc:0.816756\n",
      "[33]\ttrain-auc:0.907414\teval-auc:0.817101\n",
      "[34]\ttrain-auc:0.910488\teval-auc:0.818331\n",
      "[35]\ttrain-auc:0.910314\teval-auc:0.818317\n",
      "[36]\ttrain-auc:0.912949\teval-auc:0.817924\n",
      "[37]\ttrain-auc:0.912712\teval-auc:0.818778\n",
      "[38]\ttrain-auc:0.912352\teval-auc:0.818606\n",
      "[39]\ttrain-auc:0.915318\teval-auc:0.819388\n",
      "[40]\ttrain-auc:0.915365\teval-auc:0.819469\n",
      "[41]\ttrain-auc:0.915172\teval-auc:0.819264\n",
      "[42]\ttrain-auc:0.917509\teval-auc:0.819964\n",
      "[43]\ttrain-auc:0.917611\teval-auc:0.820041\n",
      "[44]\ttrain-auc:0.9175\teval-auc:0.82011\n",
      "[45]\ttrain-auc:0.917741\teval-auc:0.820283\n",
      "[46]\ttrain-auc:0.917762\teval-auc:0.819955\n",
      "[47]\ttrain-auc:0.9175\teval-auc:0.820138\n",
      "[48]\ttrain-auc:0.917522\teval-auc:0.820025\n",
      "[49]\ttrain-auc:0.919234\teval-auc:0.820348\n",
      "[50]\ttrain-auc:0.919099\teval-auc:0.820989\n",
      "[51]\ttrain-auc:0.922344\teval-auc:0.820642\n",
      "[52]\ttrain-auc:0.922325\teval-auc:0.821114\n",
      "[53]\ttrain-auc:0.922427\teval-auc:0.821227\n",
      "[54]\ttrain-auc:0.924353\teval-auc:0.821574\n",
      "[55]\ttrain-auc:0.924359\teval-auc:0.821627\n",
      "[56]\ttrain-auc:0.924308\teval-auc:0.821434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57]\ttrain-auc:0.925513\teval-auc:0.822098\n",
      "[58]\ttrain-auc:0.925524\teval-auc:0.822032\n",
      "[59]\ttrain-auc:0.927389\teval-auc:0.822708\n",
      "[60]\ttrain-auc:0.928343\teval-auc:0.823112\n",
      "[61]\ttrain-auc:0.930269\teval-auc:0.82354\n",
      "[62]\ttrain-auc:0.931701\teval-auc:0.823757\n",
      "[63]\ttrain-auc:0.931591\teval-auc:0.823774\n",
      "[64]\ttrain-auc:0.933034\teval-auc:0.82367\n",
      "[65]\ttrain-auc:0.932902\teval-auc:0.823625\n",
      "[66]\ttrain-auc:0.933065\teval-auc:0.823595\n",
      "[67]\ttrain-auc:0.9332\teval-auc:0.823701\n",
      "[68]\ttrain-auc:0.934811\teval-auc:0.823548\n",
      "[69]\ttrain-auc:0.936959\teval-auc:0.824354\n",
      "[70]\ttrain-auc:0.936951\teval-auc:0.824391\n",
      "[71]\ttrain-auc:0.938699\teval-auc:0.824521\n",
      "[72]\ttrain-auc:0.938649\teval-auc:0.824536\n",
      "[73]\ttrain-auc:0.938717\teval-auc:0.824652\n",
      "[74]\ttrain-auc:0.938771\teval-auc:0.824624\n",
      "[75]\ttrain-auc:0.938778\teval-auc:0.824831\n",
      "[76]\ttrain-auc:0.940517\teval-auc:0.825358\n",
      "[77]\ttrain-auc:0.940591\teval-auc:0.825363\n",
      "[78]\ttrain-auc:0.940513\teval-auc:0.825172\n",
      "[79]\ttrain-auc:0.940476\teval-auc:0.82506\n",
      "[80]\ttrain-auc:0.940449\teval-auc:0.825314\n",
      "[81]\ttrain-auc:0.940408\teval-auc:0.825465\n",
      "[82]\ttrain-auc:0.940362\teval-auc:0.825278\n",
      "[83]\ttrain-auc:0.941919\teval-auc:0.825566\n",
      "[84]\ttrain-auc:0.941892\teval-auc:0.825486\n",
      "[85]\ttrain-auc:0.941838\teval-auc:0.825492\n",
      "[86]\ttrain-auc:0.941899\teval-auc:0.825844\n",
      "[87]\ttrain-auc:0.941899\teval-auc:0.825872\n",
      "[88]\ttrain-auc:0.941957\teval-auc:0.825849\n",
      "[89]\ttrain-auc:0.941975\teval-auc:0.82583\n",
      "[90]\ttrain-auc:0.942729\teval-auc:0.825817\n",
      "[91]\ttrain-auc:0.942697\teval-auc:0.825909\n",
      "[92]\ttrain-auc:0.942666\teval-auc:0.826077\n",
      "[93]\ttrain-auc:0.943902\teval-auc:0.825714\n",
      "[94]\ttrain-auc:0.943926\teval-auc:0.825673\n",
      "[95]\ttrain-auc:0.943944\teval-auc:0.825859\n",
      "[96]\ttrain-auc:0.943939\teval-auc:0.826025\n",
      "[97]\ttrain-auc:0.944978\teval-auc:0.825846\n",
      "[98]\ttrain-auc:0.94496\teval-auc:0.825931\n",
      "[99]\ttrain-auc:0.945731\teval-auc:0.825923\n",
      "[100]\ttrain-auc:0.945764\teval-auc:0.825875\n",
      "[101]\ttrain-auc:0.945759\teval-auc:0.825904\n",
      "[102]\ttrain-auc:0.945671\teval-auc:0.826087\n",
      "[103]\ttrain-auc:0.946557\teval-auc:0.826086\n",
      "[104]\ttrain-auc:0.946603\teval-auc:0.826042\n",
      "[105]\ttrain-auc:0.947054\teval-auc:0.826247\n",
      "[106]\ttrain-auc:0.94862\teval-auc:0.8259\n",
      "[107]\ttrain-auc:0.948602\teval-auc:0.825801\n",
      "[108]\ttrain-auc:0.948579\teval-auc:0.825663\n",
      "[109]\ttrain-auc:0.948617\teval-auc:0.825624\n",
      "[110]\ttrain-auc:0.949598\teval-auc:0.825389\n",
      "[111]\ttrain-auc:0.950785\teval-auc:0.825521\n",
      "[112]\ttrain-auc:0.950722\teval-auc:0.825472\n",
      "[113]\ttrain-auc:0.95187\teval-auc:0.825963\n",
      "[114]\ttrain-auc:0.951898\teval-auc:0.825994\n",
      "[115]\ttrain-auc:0.952983\teval-auc:0.826499\n",
      "[116]\ttrain-auc:0.953831\teval-auc:0.82734\n",
      "[117]\ttrain-auc:0.953734\teval-auc:0.827375\n",
      "[118]\ttrain-auc:0.953691\teval-auc:0.827188\n",
      "[119]\ttrain-auc:0.953621\teval-auc:0.827183\n",
      "[120]\ttrain-auc:0.95358\teval-auc:0.827043\n",
      "[121]\ttrain-auc:0.953496\teval-auc:0.82695\n",
      "[122]\ttrain-auc:0.954391\teval-auc:0.826989\n",
      "[123]\ttrain-auc:0.954508\teval-auc:0.826934\n",
      "[124]\ttrain-auc:0.95538\teval-auc:0.826695\n",
      "[125]\ttrain-auc:0.956444\teval-auc:0.826559\n",
      "[126]\ttrain-auc:0.956374\teval-auc:0.826278\n",
      "[127]\ttrain-auc:0.956407\teval-auc:0.826232\n",
      "Stopping. Best iteration:\n",
      "[117]\ttrain-auc:0.953734\teval-auc:0.827375\n",
      "\n",
      "[0]\ttrain-auc:0.750655\teval-auc:0.656443\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.807461\teval-auc:0.737985\n",
      "[2]\ttrain-auc:0.821349\teval-auc:0.758732\n",
      "[3]\ttrain-auc:0.828556\teval-auc:0.769355\n",
      "[4]\ttrain-auc:0.833925\teval-auc:0.776733\n",
      "[5]\ttrain-auc:0.835011\teval-auc:0.781219\n",
      "[6]\ttrain-auc:0.835736\teval-auc:0.78194\n",
      "[7]\ttrain-auc:0.846693\teval-auc:0.786679\n",
      "[8]\ttrain-auc:0.849153\teval-auc:0.791854\n",
      "[9]\ttrain-auc:0.848788\teval-auc:0.79366\n",
      "[10]\ttrain-auc:0.860276\teval-auc:0.796294\n",
      "[11]\ttrain-auc:0.860313\teval-auc:0.796819\n",
      "[12]\ttrain-auc:0.865646\teval-auc:0.796881\n",
      "[13]\ttrain-auc:0.865558\teval-auc:0.798565\n",
      "[14]\ttrain-auc:0.874077\teval-auc:0.799088\n",
      "[15]\ttrain-auc:0.873314\teval-auc:0.799996\n",
      "[16]\ttrain-auc:0.873115\teval-auc:0.801034\n",
      "[17]\ttrain-auc:0.872649\teval-auc:0.801866\n",
      "[18]\ttrain-auc:0.872184\teval-auc:0.803034\n",
      "[19]\ttrain-auc:0.877227\teval-auc:0.80435\n",
      "[20]\ttrain-auc:0.881315\teval-auc:0.80456\n",
      "[21]\ttrain-auc:0.887406\teval-auc:0.804879\n",
      "[22]\ttrain-auc:0.886726\teval-auc:0.804386\n",
      "[23]\ttrain-auc:0.890522\teval-auc:0.804239\n",
      "[24]\ttrain-auc:0.894916\teval-auc:0.805832\n",
      "[25]\ttrain-auc:0.894248\teval-auc:0.806428\n",
      "[26]\ttrain-auc:0.897942\teval-auc:0.806935\n",
      "[27]\ttrain-auc:0.898116\teval-auc:0.808674\n",
      "[28]\ttrain-auc:0.902936\teval-auc:0.807729\n",
      "[29]\ttrain-auc:0.902628\teval-auc:0.808362\n",
      "[30]\ttrain-auc:0.902465\teval-auc:0.808856\n",
      "[31]\ttrain-auc:0.90578\teval-auc:0.810398\n",
      "[32]\ttrain-auc:0.905581\teval-auc:0.811081\n",
      "[33]\ttrain-auc:0.908633\teval-auc:0.81161\n",
      "[34]\ttrain-auc:0.912332\teval-auc:0.810651\n",
      "[35]\ttrain-auc:0.911967\teval-auc:0.810722\n",
      "[36]\ttrain-auc:0.914159\teval-auc:0.810537\n",
      "[37]\ttrain-auc:0.913907\teval-auc:0.811007\n",
      "[38]\ttrain-auc:0.913839\teval-auc:0.811812\n",
      "[39]\ttrain-auc:0.917013\teval-auc:0.812359\n",
      "[40]\ttrain-auc:0.916709\teval-auc:0.813147\n",
      "[41]\ttrain-auc:0.916415\teval-auc:0.813326\n",
      "[42]\ttrain-auc:0.919491\teval-auc:0.813569\n",
      "[43]\ttrain-auc:0.919542\teval-auc:0.814243\n",
      "[44]\ttrain-auc:0.919421\teval-auc:0.814735\n",
      "[45]\ttrain-auc:0.919129\teval-auc:0.814841\n",
      "[46]\ttrain-auc:0.91912\teval-auc:0.815526\n",
      "[47]\ttrain-auc:0.919155\teval-auc:0.81597\n",
      "[48]\ttrain-auc:0.919014\teval-auc:0.816331\n",
      "[49]\ttrain-auc:0.920562\teval-auc:0.81642\n",
      "[50]\ttrain-auc:0.920411\teval-auc:0.817253\n",
      "[51]\ttrain-auc:0.92307\teval-auc:0.817417\n",
      "[52]\ttrain-auc:0.922852\teval-auc:0.817292\n",
      "[53]\ttrain-auc:0.92262\teval-auc:0.817581\n",
      "[54]\ttrain-auc:0.92535\teval-auc:0.817864\n",
      "[55]\ttrain-auc:0.925454\teval-auc:0.818248\n",
      "[56]\ttrain-auc:0.925366\teval-auc:0.818434\n",
      "[57]\ttrain-auc:0.926101\teval-auc:0.818176\n",
      "[58]\ttrain-auc:0.926094\teval-auc:0.818191\n",
      "[59]\ttrain-auc:0.928188\teval-auc:0.818104\n",
      "[60]\ttrain-auc:0.92965\teval-auc:0.817732\n",
      "[61]\ttrain-auc:0.931138\teval-auc:0.818519\n",
      "[62]\ttrain-auc:0.932808\teval-auc:0.818478\n",
      "[63]\ttrain-auc:0.932805\teval-auc:0.818411\n",
      "[64]\ttrain-auc:0.934377\teval-auc:0.818671\n",
      "[65]\ttrain-auc:0.934297\teval-auc:0.818766\n",
      "[66]\ttrain-auc:0.934076\teval-auc:0.81916\n",
      "[67]\ttrain-auc:0.933995\teval-auc:0.819002\n",
      "[68]\ttrain-auc:0.936343\teval-auc:0.818751\n",
      "[69]\ttrain-auc:0.938189\teval-auc:0.819364\n",
      "[70]\ttrain-auc:0.938163\teval-auc:0.819534\n",
      "[71]\ttrain-auc:0.939339\teval-auc:0.819207\n",
      "[72]\ttrain-auc:0.939323\teval-auc:0.819379\n",
      "[73]\ttrain-auc:0.939315\teval-auc:0.819444\n",
      "[74]\ttrain-auc:0.939353\teval-auc:0.819738\n",
      "[75]\ttrain-auc:0.939308\teval-auc:0.819851\n",
      "[76]\ttrain-auc:0.941086\teval-auc:0.820093\n",
      "[77]\ttrain-auc:0.941033\teval-auc:0.82032\n",
      "[78]\ttrain-auc:0.940969\teval-auc:0.820434\n",
      "[79]\ttrain-auc:0.940808\teval-auc:0.820471\n",
      "[80]\ttrain-auc:0.940781\teval-auc:0.820278\n",
      "[81]\ttrain-auc:0.940815\teval-auc:0.820513\n",
      "[82]\ttrain-auc:0.940744\teval-auc:0.820625\n",
      "[83]\ttrain-auc:0.942037\teval-auc:0.821167\n",
      "[84]\ttrain-auc:0.941987\teval-auc:0.821426\n",
      "[85]\ttrain-auc:0.941978\teval-auc:0.821927\n",
      "[86]\ttrain-auc:0.941826\teval-auc:0.822341\n",
      "[87]\ttrain-auc:0.941931\teval-auc:0.822655\n",
      "[88]\ttrain-auc:0.941946\teval-auc:0.822758\n",
      "[89]\ttrain-auc:0.941886\teval-auc:0.82291\n",
      "[90]\ttrain-auc:0.942776\teval-auc:0.822503\n",
      "[91]\ttrain-auc:0.942617\teval-auc:0.822441\n",
      "[92]\ttrain-auc:0.942624\teval-auc:0.822544\n",
      "[93]\ttrain-auc:0.943957\teval-auc:0.822332\n",
      "[94]\ttrain-auc:0.943845\teval-auc:0.822454\n",
      "[95]\ttrain-auc:0.943872\teval-auc:0.822408\n",
      "[96]\ttrain-auc:0.943881\teval-auc:0.822499\n",
      "[97]\ttrain-auc:0.94495\teval-auc:0.822189\n",
      "[98]\ttrain-auc:0.945002\teval-auc:0.82216\n",
      "[99]\ttrain-auc:0.94582\teval-auc:0.822318\n",
      "Stopping. Best iteration:\n",
      "[89]\ttrain-auc:0.941886\teval-auc:0.82291\n",
      "\n",
      "[0]\ttrain-auc:0.74563\teval-auc:0.643334\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 10 rounds.\n",
      "[1]\ttrain-auc:0.812315\teval-auc:0.718749\n",
      "[2]\ttrain-auc:0.819831\teval-auc:0.733185\n",
      "[3]\ttrain-auc:0.833779\teval-auc:0.754862\n",
      "[4]\ttrain-auc:0.837347\teval-auc:0.762739\n",
      "[5]\ttrain-auc:0.836625\teval-auc:0.762793\n",
      "[6]\ttrain-auc:0.837822\teval-auc:0.765639\n",
      "[7]\ttrain-auc:0.847802\teval-auc:0.77046\n",
      "[8]\ttrain-auc:0.850364\teval-auc:0.77483\n",
      "[9]\ttrain-auc:0.851981\teval-auc:0.778236\n",
      "[10]\ttrain-auc:0.863778\teval-auc:0.781701\n",
      "[11]\ttrain-auc:0.863659\teval-auc:0.782398\n",
      "[12]\ttrain-auc:0.868062\teval-auc:0.783401\n",
      "[13]\ttrain-auc:0.868012\teval-auc:0.783819\n",
      "[14]\ttrain-auc:0.876291\teval-auc:0.787455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\ttrain-auc:0.875287\teval-auc:0.78791\n",
      "[16]\ttrain-auc:0.875509\teval-auc:0.78972\n",
      "[17]\ttrain-auc:0.87596\teval-auc:0.791015\n",
      "[18]\ttrain-auc:0.875717\teval-auc:0.791357\n",
      "[19]\ttrain-auc:0.88\teval-auc:0.791968\n",
      "[20]\ttrain-auc:0.884628\teval-auc:0.791323\n",
      "[21]\ttrain-auc:0.889043\teval-auc:0.791591\n",
      "[22]\ttrain-auc:0.888538\teval-auc:0.791445\n",
      "[23]\ttrain-auc:0.892176\teval-auc:0.791819\n",
      "[24]\ttrain-auc:0.896604\teval-auc:0.792496\n",
      "[25]\ttrain-auc:0.896054\teval-auc:0.793957\n",
      "[26]\ttrain-auc:0.899604\teval-auc:0.79362\n",
      "[27]\ttrain-auc:0.899613\teval-auc:0.795007\n",
      "[28]\ttrain-auc:0.904241\teval-auc:0.795301\n",
      "[29]\ttrain-auc:0.904124\teval-auc:0.795487\n",
      "[30]\ttrain-auc:0.903757\teval-auc:0.796382\n",
      "[31]\ttrain-auc:0.907588\teval-auc:0.796393\n",
      "[32]\ttrain-auc:0.907412\teval-auc:0.797142\n",
      "[33]\ttrain-auc:0.910359\teval-auc:0.797314\n",
      "[34]\ttrain-auc:0.913049\teval-auc:0.797949\n",
      "[35]\ttrain-auc:0.912736\teval-auc:0.797838\n",
      "[36]\ttrain-auc:0.914612\teval-auc:0.797895\n",
      "[37]\ttrain-auc:0.914332\teval-auc:0.798509\n",
      "[38]\ttrain-auc:0.914142\teval-auc:0.799007\n",
      "[39]\ttrain-auc:0.917237\teval-auc:0.79862\n",
      "[40]\ttrain-auc:0.917157\teval-auc:0.798932\n",
      "[41]\ttrain-auc:0.917182\teval-auc:0.799479\n",
      "[42]\ttrain-auc:0.919697\teval-auc:0.799702\n",
      "[43]\ttrain-auc:0.919711\teval-auc:0.800366\n",
      "[44]\ttrain-auc:0.919511\teval-auc:0.800901\n",
      "[45]\ttrain-auc:0.91947\teval-auc:0.801\n",
      "[46]\ttrain-auc:0.919378\teval-auc:0.801312\n",
      "[47]\ttrain-auc:0.919246\teval-auc:0.801887\n",
      "[48]\ttrain-auc:0.919186\teval-auc:0.802204\n",
      "[49]\ttrain-auc:0.92103\teval-auc:0.801952\n",
      "[50]\ttrain-auc:0.921215\teval-auc:0.802246\n",
      "[51]\ttrain-auc:0.924124\teval-auc:0.802767\n",
      "[52]\ttrain-auc:0.924266\teval-auc:0.802731\n",
      "[53]\ttrain-auc:0.924283\teval-auc:0.802902\n",
      "[54]\ttrain-auc:0.925674\teval-auc:0.802929\n",
      "[55]\ttrain-auc:0.92561\teval-auc:0.803637\n",
      "[56]\ttrain-auc:0.925537\teval-auc:0.803723\n",
      "[57]\ttrain-auc:0.927318\teval-auc:0.803941\n",
      "[58]\ttrain-auc:0.927312\teval-auc:0.803813\n",
      "[59]\ttrain-auc:0.929393\teval-auc:0.803762\n",
      "[60]\ttrain-auc:0.930918\teval-auc:0.803661\n",
      "[61]\ttrain-auc:0.93278\teval-auc:0.803943\n",
      "[62]\ttrain-auc:0.934222\teval-auc:0.804466\n",
      "[63]\ttrain-auc:0.934179\teval-auc:0.804634\n",
      "[64]\ttrain-auc:0.935983\teval-auc:0.804306\n",
      "[65]\ttrain-auc:0.93588\teval-auc:0.804637\n",
      "[66]\ttrain-auc:0.935908\teval-auc:0.805153\n",
      "[67]\ttrain-auc:0.935944\teval-auc:0.805434\n",
      "[68]\ttrain-auc:0.937137\teval-auc:0.805507\n",
      "[69]\ttrain-auc:0.938591\teval-auc:0.806133\n",
      "[70]\ttrain-auc:0.938647\teval-auc:0.806346\n",
      "[71]\ttrain-auc:0.940271\teval-auc:0.806661\n",
      "[72]\ttrain-auc:0.94014\teval-auc:0.80688\n",
      "[73]\ttrain-auc:0.9403\teval-auc:0.806912\n",
      "[74]\ttrain-auc:0.940286\teval-auc:0.806932\n",
      "[75]\ttrain-auc:0.940299\teval-auc:0.807223\n",
      "[76]\ttrain-auc:0.941658\teval-auc:0.807343\n",
      "[77]\ttrain-auc:0.941678\teval-auc:0.807631\n",
      "[78]\ttrain-auc:0.941757\teval-auc:0.80773\n",
      "[79]\ttrain-auc:0.941671\teval-auc:0.807992\n",
      "[80]\ttrain-auc:0.941747\teval-auc:0.808103\n",
      "[81]\ttrain-auc:0.94174\teval-auc:0.808203\n",
      "[82]\ttrain-auc:0.941674\teval-auc:0.808336\n",
      "[83]\ttrain-auc:0.943216\teval-auc:0.808453\n",
      "[84]\ttrain-auc:0.943202\teval-auc:0.808351\n",
      "[85]\ttrain-auc:0.943175\teval-auc:0.80836\n",
      "[86]\ttrain-auc:0.943186\teval-auc:0.808617\n",
      "[87]\ttrain-auc:0.943233\teval-auc:0.808488\n",
      "[88]\ttrain-auc:0.943243\teval-auc:0.808348\n",
      "[89]\ttrain-auc:0.943232\teval-auc:0.808416\n",
      "[90]\ttrain-auc:0.94413\teval-auc:0.808857\n",
      "[91]\ttrain-auc:0.944022\teval-auc:0.808878\n",
      "[92]\ttrain-auc:0.943955\teval-auc:0.808833\n",
      "[93]\ttrain-auc:0.945199\teval-auc:0.808811\n",
      "[94]\ttrain-auc:0.945205\teval-auc:0.808945\n",
      "[95]\ttrain-auc:0.945246\teval-auc:0.809212\n",
      "[96]\ttrain-auc:0.945208\teval-auc:0.809296\n",
      "[97]\ttrain-auc:0.946633\teval-auc:0.80952\n",
      "[98]\ttrain-auc:0.946649\teval-auc:0.8096\n",
      "[99]\ttrain-auc:0.947326\teval-auc:0.809837\n",
      "[100]\ttrain-auc:0.947396\teval-auc:0.809933\n",
      "[101]\ttrain-auc:0.947371\teval-auc:0.810012\n",
      "[102]\ttrain-auc:0.947378\teval-auc:0.810034\n",
      "[103]\ttrain-auc:0.948458\teval-auc:0.809998\n",
      "[104]\ttrain-auc:0.948668\teval-auc:0.809812\n",
      "[105]\ttrain-auc:0.949589\teval-auc:0.809438\n",
      "[106]\ttrain-auc:0.951064\teval-auc:0.809454\n",
      "[107]\ttrain-auc:0.951079\teval-auc:0.80955\n",
      "[108]\ttrain-auc:0.951037\teval-auc:0.809767\n",
      "[109]\ttrain-auc:0.95105\teval-auc:0.809651\n",
      "[110]\ttrain-auc:0.951748\teval-auc:0.809665\n",
      "[111]\ttrain-auc:0.952515\teval-auc:0.809752\n",
      "[112]\ttrain-auc:0.952466\teval-auc:0.809912\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-auc:0.947378\teval-auc:0.810034\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kya/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.828569+0.00148645\ttest-auc:0.807946+0.00626533\n",
      "[10]\ttrain-auc:0.841363+0.00150472\ttest-auc:0.816252+0.00564041\n",
      "[20]\ttrain-auc:0.845631+0.00131938\ttest-auc:0.8165+0.0055205\n",
      "[30]\ttrain-auc:0.848648+0.00150153\ttest-auc:0.816616+0.00546625\n",
      "[40]\ttrain-auc:0.851106+0.0015426\ttest-auc:0.816109+0.00568057\n",
      "\n",
      "Ensemble-CV: 0.8168388+0.0057118418185380555\n"
     ]
    }
   ],
   "source": [
    "pred = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "homedir = os.environ['HOME']\n",
    "path_test = homedir+'/data/mangaki-data-challenge/test.csv'\n",
    "test = pd.read_csv(path_test)\n",
    "\n",
    "df_pred_sub = pd.DataFrame(pred, columns=['prob_willsee'], index=test.index)\n",
    "\n",
    "df_pred_sub['prob_willsee'] = df_pred_sub['prob_willsee'].apply(lambda x: 0.0 if x < 0.0 else x)\n",
    "df_pred_sub['prob_willsee'] = df_pred_sub['prob_willsee'].apply(lambda x: 1.0 if x > 1.0 else x)\n",
    "\n",
    "pd.concat([test, df_pred_sub], axis=1).to_csv(\"mangaki_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
